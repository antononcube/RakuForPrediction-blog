My name is Anton Antonov this presentation is titled integrating large language models with raku let me start with some demonstration of the functionalties here I opened in visual studio code a new raku chatbook that's probably not the first thing to the most fundamental thing to do but it's fits nicely what Andrew was showing so here I'm going to create this is a visual studio code uh Andrew was using also Visual Studio code this is a a chatbook you can see this is a Raku chatbook um kernel so this is a Jupiter notebook with a Raku chat book so if I if I ask for you know different kernels you might see different kernels being lined up here so here first I'm going to use um uh I'm going to specify open AI uh and I'm going to dictate how many people live in Brazil and ideally I'm going to get the result one of the goodies with this um is that um when you uh when you when you use this uh type of functionalities here the result from the large language models is automatically placed in the in the clipboard so this what I see I just press control V uh command V and I'm getting this result into a cell all right so I'm going to produce a new cell this is with open AI I also have connections to palm palm this is the Google large language model and so I'm going to make a new Cod cell and I'm going to say Palm here and I'm going to list different styles of Japanese paintings and so let's see what we're going to get so um actually let's actually do something here so with this uh this uh implementation of a chatbook I can specify what I want the result to be uh put into markdown and this what you see see here so when I say this when I make this specification we get the result into markdown the previous result was just plain text right so what I'm going to do here I'm going to use another I make another cell use DALL-E DALL-E is a image generation uh service by open Ai and I'm going to dictate make a Japanese style painting with Autumn landscape and let's say choose the first one right so I'm going to use say Yamato Yamato e right and so this is going to presumably produce some painting in a Japanese style whenever it comes it's thinking too long okay well seems to be the case I can also specify that I want say three paintings and I want um the size to be medium right let's see what is going to uh right let's see what is going to happen so ideally we're going to get three three paintings with this all right so what is this um thinking about this is pretty simplistic in a sense right so this direct access uh you are directly using the services provided provided by say Char GPT openi or Palm by Google right but that's not um let me the paintings right and um I can also say uh for example something else right I mean actually let's let's drop this example let's not do anything further so the direct access is um of course one way to to kind of access this Services the advantages is that we're using the web API in a fairly direct Manner and so I'm actually going to show uh something here so this is the openi playground this is a command line interface with this package Raku www upon AI I'm going to dictate what is the population of India and I'm going to evaluate this and presumably I'm going to get some results right so so all right so this is again direct access I might prefer to do something else like I might prefer to use um chat chat um chat objects and so this what I'm going to to show next so here I'm going to uh to use a a chat object I'm going to name it say Yoda Yoda one and I'm going to say what the prompt is uh is this um is this uh it's Yola and I'm going to explain what this abbreviation means and I'm going to dictate hi who are you and ideally we're going to get um a response by Yoda now from now on I can actually access this uh chat object uh with this specification and ask other questions how many students did you teach what is the color of your laser saber all right so ideally we're going to get some result now to some to some extent I should convince you that this is producing whatever the interaction here is is actually glob within this chat book right so it's not oneof evaluation so what I'm going to do next is presumably going to be convincing about that so I'm going to say um what I want the previous result to be translated into German and I'm going to specify this with the carrot symbol so translate is a function I say German the carrot symbol means the previous thing whatever it was said in that chat with this and sobly this here yeah it seems to be it seems to be pretty pretty close all right so uh this is this is the interaction with the chat objects and um before going further uh I the last example this is the last live cing example I'm going to be doing is that I'm going to show how we generate some code for example here with uh some plain chart I'm going to say show matical formulas and Raku code for solving the quadratic equation and so ideally this is going to produce something we you know related to whatever I asked and again um actually I might say look I mean I actually want this to be in this markdown output right because it's going to be more convenient and so uh so yeah you can see if I when I I said Markdown because I did say that I want mathematical formulas and uh and you know uh Raku code you can see what the Raku code has been placed in this uh in this um in this cell now this was not completed because I didn't uh it didn't specify uh there were not enough tokens by default so I can say that I want more tokens right and I mean ideally this is going to to kind of uh to produce the full output right it's going to have enough tokens to produce the full output all right so now again you know I can copy this text and you know evaluate it and Etc right so I can do some code evaluations and Etc I'm not going to go further with that all right so um this was more or less um the chatbook um discussion so I want to kind of start with the uh with the to continue you know with the conclusions actually actually so why we are doing this large language models with with Raku and so first of all we do need this type of um this type of um uh this type of um Dynamic interaction of Raku with the large language models this Dynamic interaction have to include in Notebook solution in which we actually kind of store the results and we can uh facilitate the interaction right we say automatic copying to the clip clipboard formatting of text and so forth and so this one of the motivations for big motivation to develop a framework of different functionalities with which uh uh Raku can be extended so to speak with large language models or the other way around right so Raku presumably being very good with um working with um with text extracting text uh it should be a natural type of marriage with the language models and um I'm going to try to see in the chat let me access the chats here so any questions here so far uh so uh how did I make uh the Jupiter to do that well uh a very good question uh thank you um I'm going to uh I had this open somewhere so these are the packages which I'm uh I have developed for interacting with um with um large language models there is a Jupiter chatbook package which is based on Brian Dugan's um Brian Dugan's um Jupiter oh this is not chat book it's called jupter kernel right so hopefully this is going to go to the right right link yeah so I'm I'm I'm building on top of that right and so I I um I'm using this yeah using this chatbook you know in order to use in order to use uh uh the functionalities I showed we need to have a a proper um proper kind of um interaction for this what I was showing here was the the last examples where notebook notebook wide charts right so they're contextual they throughout the whole uh notebook in order to have this I need to uh to have this fundamental functionalities right how do I specify configurations and evaluation of functions how do I specify and have in large language model chat objects so this is actually I need to I need to discuss this anyway right so here if you use Jupiter chat books uh they they understand mermaid right mermaid if you're not familiar mermaid GS is a a type of diagram specification language so you can see here uh I have this uh diagram specification and I have plotted it right so what is happening so here right again I'm continuous I'm answering the question how did I make Jupiter to do that so for each Jupiter session I have um a database of chat objects and so when you go to the Jupiter front end right when you get to the input of the cell right we kind of go okay well do we know this ID like if this if we don't specify ID there's some default ID if you specify ID like I was uh showing the ID Yoda one yd1 then that particular chart object is retrieved from the database now if there's some kind of prompt um a prompt DSL this was with um you know at Yoda right what I was showing here right so let me actually so this is a prompt DSL type of thing this is a prompt requir prompt expansion this here also did a prompt expansion so I have a database of um a database of prompts around 220 prompts and um where if you see this type of specification for prompt expansion uh it is Bank accessed so this is the package llm prompts right so you can see some examples here you know it's like basically doing that if you if you're curious to kind of see what the actual prompts are uh you can you can see in the resources uh this is how this prompt prompt Json you know all the prompts are being listed here so the advantage of this approach is that you can utilize this prompts in other languages like say I reprogram this in Python and I'm using the same prompts here I harvested the prompts uh uh from uh from the W from W from repository which let me see can I get it here V prompts so uh volr prompt repository has um yeah has few hundred um prompts and they're roughly roughly separated into personas functions and modifiers so I use the Yoda Persona and I use the function translate for example right in this particular case all right so um very good question thank you um let me kind of return back to this um to this diagram so what I was saying is that if we get uh we get the input into the uh chat book uh we find the appropriate chat object if there's no such object we create it then we go to the prompt database we do expansion if we have to and then we go to the actual uh Services which provide the which provide the large language models in this particular case I'm showing only say Palm by Google and open whatever chat GPT you can have some others like say I don't know there's a Yandex GPT there's I mean I can I I have experimented with my own uh small language models uh which can be plugged in into this whole framework all right so um maybe I should move on and not um not look further into the questions but um all right let me try to see all right so uh let me continue with the presentation so uh this um I I think I I I discussed enough motivation but I want to mention a couple of use cases here first of all this cannot be ignored large language models right everybody's I personally as a senior data scientist or senior research scientist whatever you know I'm using to Brand myself I mean everybody's asking me about this in one way or the other so some familiarity and ability to utilize it is important is this with Raku right maybe maybe not right but it doesn't matter to some extent it's a it's a great way to familiarize yourself with uh this functionalities by you know programming them I'm also having a software engineering perspective for this another thing is that um I'm very interested in uh this the so-called um template engine functionalities and I'm going to to show here actually had some example prepared let me let me browse to it like imagine you give this kind of free text so to speak I mean not arbitrary but you know extract 20 topics from the Text corpus Corpus a abstracts using the method non negative Matrix factorization show statistical Toros for the words neural function in Notebook this generates this function concretize generates uh the generates this um this code right so I wanted to implement this in Ru and I wanted to this implemented in maaa and the only reason it's implemented in maatic is is because Mathematica since four five years ago had a function called find textual answer so I wanted to do find textual answer in Raku and let me see do I have it somewhere here right so I might right uh so some so uh for me it was uh very very important to this type of functionality and in order to do that I I couldn't just stay with the simple access of large language model Services packages like www ww Palm I need to do this llm functions LM chart objects and so forth right now you can see here I have um this is the this is a Ru package right find textual answer so you can see here that I have used an exerpt from Nicholas Tesla's biography and I have asked here you know a question right where live and I said well give me three answers right and here the finder is being pal and I'm getting this results now I can have multiple questions and you can see this is my use case right so this is a uh computational workflow specification about classification right so I am asking this question which data set what is the method which Matrix to be shown and so I'm getting some results here and I can request this to be done with Pairs and I can actually have this so This result here it's already actionable if I have if I have a template for if I know how to do classification uh pip lines I can just fill in this U this arguments and produce the corresponding corresponding code and so forth all right so again you know for me this was one of the primary um use cases I didn't have time to implement this and to to kind of uh have uh to show this but for another thing is the embeddings right with um large language models you can get this related semantic analysis for free so to speak right so you can you can uh do text to send text to the large language models and uh with that you can produce certain certain vectors which then you can use to do uh to do some type of um computations let me actually show this I'm going to go to Ruland and I'm going to uh say here palm and um pal here there should be some example with embeddings maybe it's this one right so uh let me see yeah so basically you can see I have this uh free text and I have called this edings and then produce this three vectors and then I can actually do some kind of cross tabulation make some kind of inner product between them and I think uh maybe a better example about what I'm talking about is in this um open AI package I apologize I should have prepared prepared this better but yeah somewhere here right ideally this is a great example unfortunately it doesn't get displayed fairly well here so I'm going to go to go to the GitHub repository right so somewhere here we should be able to see this table right which corresponds to the embeddings so this here it's finding the inner product between the between the edings uh let me see this is the product right so anyway uh this was uh this as I say it's uh it has been a primary motivation for me because if I can do related semantic analysis in that way through the large language models I can produce recommended systems say in R right otherwise in order to do lat semantic analysis in Ru I need to implement a bunch of functionalities like sparse Matrix linear algebra and so forth right and variety of methods for factorization and so forth I already covered the prompts there are like um 220 prompts I also reprogram them in Python and I mentioned the service access here and the command line interface so uh let's go to uh this literate programming um application before doing that let me look into the questions here comments in the chat maybe there's a question actually if anyone has any questions please do ask all right so um the Markdown templates and that's a fun example it's um it's one of the maybe motivations to let me locate it here so um imagine what you want to tell people how they should um quit python right and and uh and do something else right like say use Raku so I mean this this this an example template so some of the end products here let me find it right so I think it's this one you know yeah 12 steps guide to quit Python and replace it with r right so this is a generated document using large language models and so I mean you can see here but you know like yeah you should acknowledge your addiction to programming in Python and you should I know you should delete the the python whatever right and so forth right and then there should be some kind of steps about rco at some point so what is happening here there is like this template which you can see it's this a markdown document right so if you look at this uh this a markdown uh document right and I have this um let me see how well I have this code cells right which say um which say that we're going to be using this packages for example and we want to hide the results and we don't want this cell to be seen so this is what this parameters say and then uh there's a section called simply put right so this is what we see here this is this section and in this section we say uh okay well generate seven steps outline list uh with Arabic numerals with B prefixes for item and so forth right H this is here for all but same goes for Python and whatever it is and I'm actually giving some hints why why uh this uh what this list should contain so again you know you can see I'm specifying certain values for the actual for the actual Palm for the actual Service uh how to be uh how to be invoked what parameters number of tokens you know temperature and so forth and I'm also saying but this the this cell itself shouldn't be Echo right and so and the the other the other thing is that um when the effect of this is that we are going to have this section which looks like a you know like a generated document written right there's no you don't see the the blueprint so to speak with the Raku code which generated this this section and similarly we can have um instead of having open sorry open a or Pal or some large language model uh cell here I can have a uh pearl of six or Raku rusel in which I'm actually saying how the how to expand on each of these questions so basically I'm using large language models here to expand upon each of the each of the points which have been generated and so this is what you see here and I'm also saying that you know this should be used as a the text should be quoted and the section should be numbered and so forth right so um this this is a very interesting technique uh I uh again I developed this um probably like two years ago I was heavily borrowing from ideas from Brian Dugan's package on Jupiter kernel so this this is a computational markdown I mean I I've been discussing this in variety of um in variety of my um my blog posts uh so and I consider it to be a fairly fairly useful technique in general right this is most of the time how I generate the documentation for for my raakup Pak PES right I have a I have a a computational rmy and this computational rmy produces the uan version of of it all right so uh going uh going to to other examples here uh very interesting perspective is to for for doing is gener generating test from descriptions so we can do uh we can use plain text or we can use ging examples and I think I I prepared I prepared a diagram for this but maybe I hav't I haven't included it here I'm not going to I'm not going to uh look too diligently for this but I do want to mention uh that package about gin it's U it's an it's a relatively easy to to think about using um large language models in that way because in general uh gin is is uh is made to to actually deal with um with uh natural text right we specify we specify our the way we specify our scenarios like what you see here right we can specify but we have this feature we have a scenario we specify uh certain rules and then some some code is being generated and we can do this both ways right we can generate code from gin and you can generate Gin from from the code right and so this is what this uh this example is referring to this is probably more interesting um this is generating a package documentation from from tests uh many people who are who are going to be um publishing packages who are publishing and going to be publishing packages in say Rand they do provide the test but they don't provide document ation maybe uh Marton is going to discuss this uh but one of the things to to provide documentation at least nominal documentation is to use large language models with minimal hinting minimal prompting and um using say certain um using using tests to to produce the documentation summarizing quties there summarizing doesn't work about well I mean in the sense you need to kind of go through uh through the through the uh through the documentation in order to generalize it I um I think I have several examples about that but I don't I'm not sure how interesting this is so um the other is that um yeah let's actually do this conversation between two characters so imagine you have two chat objects and you want to you want to make them Converse so here I'm actually trying to find a particular notebook with this so um yeah let me zoom out zoom in here and um so I can have U Man versus machine machine versus man and so forth right obviously we can have Machine versus machine so somewhere here I hope I have this let me see it's um it's a simple there basically two prompts right one for the the Oracle one for the guesser and then I have a simple Loop in which they interact with each other they're basically feeding each other's guesses and results and you know so basically I do need to provide some kind of secret number to be evaluated beforehand right then you know there's some kind of discussion what is the secret number and is this is that it's less whatever sometimes people get you know the conversation and the the the people who are talking of the people the personas the large language moral person who are talking here they get confused but you know it's an interesting interesting uh type of use case so what is the what is be more interesting application about this imagine that you want to produce different dialogues for training purposes like say clerks in hotels or some kind of commodity uh Goods shipping kind of company and and Etc right so some kind of um dialogues that can be used for training that can be used for like say testing the system and so forth right all right so um this is this was all you know from this literate programming perspective I'm going to be discussing um large language um work workflows actually a very important um um example here is something I don't I I really want to discuss and it's not listed here this is uh this is about um um to Long didn't read documentation utilization and uh uh so as an example we are going to look into uh the Raku package app which um is developed by Elizabeth mat so so somewhere here I think I have it right so and so what is the what is the idea here this package is way too way too large it has 127 or 200 whatever parameters right and so instead of um instead of um reading all the documentation which was diligently provided by Elizabeth let me actually see where where is this right so ideally somewhere here right there you can see I have this we have this markdown documents right now I can just take just but I can take this um this code Snippets here so the rock code is being pref prefixed so to speak or there is a comment here and so imagine I can use this for training I can basically make the so called few shot training in um large language models and I can say Okay given this kind of text you need to produce this kind of text right so and uh this is what uh what this um uh this the procedure is here I'm taking all of the all of the documents related to this to AA the package markdown grammar um knows how to par um knows at this point how to parse markdown uh documents and extract code code fragments and from this I make this comment and code pairs I extract them I make the corresponding large language model example function to to translate to make this translation from the natural language commands to the upera commands and then uh then of course we need to test it so so I'm not going to go through all of the elements here this is basically the different blocks are being uh taken you can see I have this key I have this value so basically this is my training set um I can um uh after I have produced the corresponding um examples I can I of course I need to verify one way is to ask the large language models to produce s 10 or 20 or 200 random statements random requests for doing um what ARA is supposed to be doing like finding files uh in in a in a directory and so so it's it is something which is a fairly well-known playground right and so they this can be this can be easily it is easily produced and then we need to basically so this what I'm discussing here right so I have generated the random commands right and I have also generating the corresponding UPA it's an interesting question is are this are this correct the commands which are being generated are they correct do they run and if they run do they actually so they might not run right they might be just not executable but if they executable do they produce what was actually requested this is actually not that hard to really uh stage as tests but you know I I haven't done it all right so I'm going to Andrew how we have time how much more minutes do I have I think some kind of nine minutes okay well um so yeah I wanted to discuss comparison with python and and V from language or Mathematica and actually this is probably it's a it's a nice way to kind of do that so let me bring um this particular notebook here I'm going to close uh some of this let me open so I think I had this all right so uh this is probably the more important um um more important um software engineering from software engineering perspective part of the talk so large language models they hallucinate results they're not reliable you shouldn't trust them and U if you want to use them in certain computational workflows what exactly do you do and so one of the ways to to do that is to actually uh have this large language model functions which let you specify let me zoom in here which let you specify certain templates you can see this is a string template or this is a pure function whatever you call it right in in Raku so and you can specify certain configurations in this particular case I'm saying but I want to uh use open AI with a certain temperature also I'm saying but I want the result to be uh to be the result I have set here in the function itself but I want the result to be in Json but I'm also saying with this form what the the so called Subara Json Subara needs to be applied so when I apply this function so which which was created here you can see how these arguments GDP top 10 largest countries in 2022 have been fil in it is what is the GDP of the top 10 largest countries in 2022 give the results in as a name number dictionary in Json format right so we get here because I applied this Subara Json I I can you can see this is actually Raku Raku code right and this is a Raku hash uh hash object and so here I actually visualize it in some way I'm using here I'm using here one of the functions for data re Shapers so now there's an interesting thing here if I want to plot this data and do something with it right what do we do with this trillion USD I this is very inconvenient so this can be handled handled in several ways we can actually have another large language model function which let us um let us um remove this right remove this uh this code right alternatively I can just do it with Raku use my Raku prowess so to speak to manipulate text and so and then after I have done this I want to do this you know I want to do this plotting in this particular case I have a Subara which is numeric since all of this are trillion USD and say I'm interested in all of this have trillion USD as a suffix right and I'm interested in a comparative type of plot you can see with this subar numeric I'm just getting those numerical results and I'm making this uh text plot instead of using this textual plot I'm I can also use a JavaScript plot which does this bar bar charts and Etc I have discussed this in in some of my blogs about in some videos about using JavaScript plotting right using Raku specifications for U for producing um uh JavaScript plots all right so here uh I'm going to move next to there some other examples about um data data retrieval and plotting and whatnot and this is the example function I was talking about so this is also the so-called few shot examples which I was using to do uh the too long didn't read documentation training so you can see here how this some numbers with commas have been translated into some kind of proper Raku Ru specifications and here you see the million trillion and so forth right so all right so then if I this example function so this is a large language model function this large language models they do facilitate example functions so uh we can see here how I have applied it to to the output above and we're producing you know something this N Norm this normalization function here is producing well normalized results um very interestingly and I'm going to uh to to kind of go to this uh section here is the conversion uh to Ru objects so imagine you want to ask certain questions which are related to say physics chemistry whatever it is biology and you have corresponding Ru packages that can deal with those and so here uh you can see like I have this example function again which tells me how the numerical results should be interpreted in a certain um certain type of Raku code this is a package written by Steve R physics units and so you can see here like I'm asking what is the average speed of whatever in units of whatever right and so we're looking say rocket leing curve meters per second we get this result now I apply my uh my example function here and then we get this code now if I evaluate it I'm getting this object right so and then I can manipulate it further similarly or similarly but uh imagine you want to do certain chemical computations right and so here this is actually showing some stochiometry formulas being manipulated in this way so I'm requesting three formulas which include sulfur and so and then I I get these formulas it's an interesting question are they balance they're not and this one of the proofs that um large language models hallucinate the results so I might want to verify uh this uh this balancing I want to I can probably want to do the balancing myself and so forth and this what is happening here um a very interesting point uh in application is to do name entity recognition which is a relatively difficult um problem and so here this example shows how we can um well actually it doesn't show anyway uh if this worked right I should have revaluated this so uh the idea is that we can extract album names and ears from uh from text which has been generated right say uh I have used the large language moral access to to extract certain certain biography of a certain singer and then you know I'm actually asking you know different different results different elements of it like say uh the discography to be to be done you can see it actually here done for uh for a bunch of artists right so I have generated random artists like Tor Swift Adele and so forth right so this is when this actually work a very interesting thing is can you can you can you rely can you get reliably the same results when you're asking this so I use this package uh which is called type system I use it for other purposes and this type system you can see I mean you can make some kind of Statistics this is the purpose for this we using this package type system I can make some statistics uh uh around um around um uh the evaluation of the large language models and see how reliable they might be in some computational workflows so uh I don't think I have time to do the comparison but you can see I did reprogram uh the Jupiter chatbook into a python chat book and if you're interested you can can say you know uh see it somewhere here you can see it in piy orc whatever right and um there certain correspondence right with corresponding V from language functionalities I mean I have heavily borrowed ideas from them and I think this um this um finishes my presentation any questions hi Anton I have a question uh this is so thanks for the thanks for the shout out especially and um thanks love love the chatbook um I guess one question for me is um is what other sort of fundamental features do you think would be useful um from the kernel um I see like a lot of stuff with the Magics um that's that's um sort of pushing the boundaries of what's built in and are there any other sort of deeper issues you know with either with the kernel or with like the Jupiter architecture in general that are like limitations um this is a I can have very long and Confused answer for this but um one of the one of the reasons I would say I did this comparison right comparison implementation in Jupiter uh Jupiter framework in Python is that it's uh it's impressive how easy it is to to add new functionalities into into to extend the Jupiter framework for python right they have a very streamlined way of doing of doing that it is uh it is uh it was surprisingly easy to some extent that's why I I did it if I had to do the same work which I did with um with Ru I wouldn't have I wouldn't have done it I mean and I'm sorry if I'm talking python here but you can see like say the actual code I mean python being very you know spread out language so to speak but if you look at the actual code it's not that it's not that big it's mostly me specifying how to do how to to parse the different arguments and then after that you know it's just kind of uh calling the underlying functions of course I have this prompt functions and large language model functions packages implemented already but one of the greatest advantage of using python is what the the corresponding large language model Services they already provide the access to those large language models right in Python and so for me this was a great speed up one of the consequences of this is that it's actually uh you cannot have such a nice detailed detailed specification of parameters with python you need to follow a certain a certain uh a certain uh type of uh of specifications let me actually bring some example here this is the this is the python Jupiter chatbook right so I need to uh load the load the magic right and I'm for example you see you you have provided this redirection to Markdown here I need to specify but I want the result to be marked down so we're using a command line type of specifications to do the do the the Magics that's actually convenient because everybody more or less knows the command line specifications I guess right and people need to be trained in the Raku style but with the Raku style of magics I can do arbitrarily you know arbitrarily convenient magic so to speak right and so another thing to mention here is that right I mean it is like when I have this Meta Meta objects right to access this this um to access the the chat objects database it is I mean I had to make certain decisions in uh in Python right for this now what exactly is would be better right for the Jupiter framework do you envision some other people to be extending um extending Jupiter Jupiter kernel relatively easily the way I did right but I mean M my extension was not easy right I mean but I'm claiming the one is easy but then if you do it is it worth it right who I mean I honestly and I'm being obnoxious here probably but ra Community is not that interested in in Jupiter right in the Jupiter framework so I'm sorry I'm talking on and on so hopefully I answered your question so yeah good thanks yeah I mean and I was also just wondering anything besides Magics that were that were sort of limits um okay yes like say um I mean the extensions they can be grouped in two ways right uh they can be grouped into accessing external services like say this mermaid diagrams like what you see here right uh I I have made a Mermaid Magic right which basically takes this code right this mermaid code and sends it to mermaid Inc mermaid Inc is a is a you know so you might decide to to kind of streamline this type of this type of functionality right like because I do it like another thing is deep L right this is a a service for translating languages right they use neural networks and Etc but imagine I want to also have like some DL and put some language here and gets getting translated and so forth right so I have variety of use cases which arejust this I have certain package say ww blah blah in uh in in Ru and I want to very easily plug in this into a cell in Jupiter so I would say this can be this can be a good enough architectural challenge which is worth putting so to speak in the mainstream jup kernel do it make sense hope thanks M right other questions um I need to see chat messages I guess and um okay well uh yeah I assume that was it thank you for your attention yeah cool thanks thanks a lot so