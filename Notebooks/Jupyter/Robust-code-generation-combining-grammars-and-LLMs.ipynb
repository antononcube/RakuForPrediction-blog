{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f36935",
   "metadata": {},
   "source": [
    "# Robust code generation combining grammars and LLMs\n",
    "\n",
    "Anton Antonov  \n",
    "RakuForPrediction at WordPress   \n",
    "October, December 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5777b8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8010b",
   "metadata": {},
   "source": [
    "This document (notebook) discusses different combinations of Grammar-Based Parser-Interpreters (GBPI) and Large Language Models (LLMs) to generate executable code from Natural Language Computational Specifications (NLCM). We have the _soft_ assumption that the NLCS adhere to a certain relatively small Domain Specific Language (DSL) or use terminology from that DSL. Another assumption is that the target software packages are not necessarily well-known by the LLMs, i.e. direct LLM requests for code using them would produce meaningless results.\n",
    "\n",
    "We want to do such combinations because:\n",
    "\n",
    "- GBPI are fast, precise, but with a narrow DSL scope\n",
    "- LLMs can be unreliable and slow, but a wide DSL scope \n",
    "\n",
    "Because of GBPI and LLMs complementary technologies with similar and overlapping goals the possible combinations are many. \n",
    "We concentrate on two of the most straightforward designs: (1) judged parallel methods execution, and (2) using LLMs as a fallback method if grammar parsing fails. We show [asynchronous programming](https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)) implementations for both designs using the package [LLM::Graph](https://raku.land/zef:antononcube/LLM::Graph).\n",
    "\n",
    "The Machine Learning (ML) package [\"ML::SparseMatrixRecommender\"](https://raku.land/zef:antononcube/ML::SparseMatrixRecommender) is used to demonstrate that the generated code is executable. (Here that package is used not as much as a recommender but as a search engine.) \n",
    "\n",
    "\n",
    "The rest of the document is structured as follows:\n",
    "\n",
    "- Initial grammars-LLMs combinations\n",
    "    - Assumptions, straightforward designs, and trade-offs\n",
    "- Comprehensive combinations enumeration (attempt)\n",
    "    - Tabular and morphological analysis breakdown\n",
    "- Three methods for parsing ML DSL specs into Raku code \n",
    "    - One grammar-based, two LLM-based\n",
    "- Parallel execution with an LLM judge\n",
    "    - Straightforward, but computationally wasteful and expensive\n",
    "- Grammar-to-LLMs fallback mechanism\n",
    "    - The easiest and most robust solution\n",
    "- Concluding comments and observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae11369",
   "metadata": {},
   "source": [
    "\n",
    "### TL;DR\n",
    "\n",
    "- Combining grammars and LLMs produces robust translators.\n",
    "- Three translators with different faithfulness and coverage are demonstrated and used.\n",
    "- Two of the simplest, yet effective, combinations are implemented and demonstrated.\n",
    "    - Parallel race and grammar-to-LLM fallback.\n",
    "- Asynchronous implementations with LLM-graphs are a very good fit!\n",
    "    - Just look at the LLM-graph plots (and be done reading.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a9d20",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Initial Combinations and Associated Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b394f2",
   "metadata": {},
   "source": [
    "The goal is to combine the core features of Raku with LLMs to achieve robust parsing and interpretation of computational workflow specifications.\n",
    "\n",
    "Here are some example combinations of these approaches:\n",
    "\n",
    "1. A few methods, both grammar-based and LLM-based, are initiated in parallel. Whichever method produces a correct result first is selected as the answer. \n",
    "   - This approach assumes that when the grammar-based methods are effective, they will finish more quickly than the LLM-based methods.\n",
    "\n",
    "2. The grammar method is invoked first; if it fails, an LLM method (or a sequence of LLM methods) is employed.\n",
    "\n",
    "3. LLMs are utilized at the grammar-rule level to provide matching objects that the grammar can work with.\n",
    "\n",
    "4. If the grammar method fails, an LLM normalizer for user commands is invoked to generate specifications that the grammar can parse.\n",
    "\n",
    "5. It is important to distinguish between declarative specifications and those that prescribe specific steps. \n",
    "   - The grammar parser may successfully parse most steps, but LLMs may be required for a few exceptions.\n",
    "\n",
    "The main trade-off in these approaches is as follows:\n",
    "\n",
    "- Grammar methods are challenging to develop but can be very fast and precise.\n",
    "   - Precision can be guaranteed and rigorously tested.\n",
    "  \n",
    "- LLM methods are quicker to develop but tend to be slower and can be unreliable, particularly for less popular workflows, programming languages, and packages.\n",
    "\n",
    "Also, combinations based on LLM tools (aka LLM external function calling) are not considered because LLM-tools invocation is to unpredictable and unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd382b01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comprehensive breakdown (attempt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806f075",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe01e98",
   "metadata": {},
   "source": [
    "Here are the packages used in this document (notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df02b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "use DSL::Translators;\n",
    "use DSL::Examples;\n",
    "use ML::NLPTemplateEngine;\n",
    "\n",
    "use LLM::Graph;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b894d01",
   "metadata": {},
   "source": [
    "Here are LLM-models access configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c77e5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my $conf41-mini = llm-configuration('ChatGPT', model => 'gpt-4.1-mini', temperature => 0.45);\n",
    "sink my $conf41 = llm-configuration('ChatGPT', model => 'gpt-4.1', temperature => 0.45);\n",
    "sink my $conf51 = llm-configuration('ChatGPT', model => 'gpt-5.1', reasoning-effort => 'none');\n",
    "sink my $conf51-codex = llm-configuration('ChatGPT', path => 'responses', model => 'gpt-5.1-codex');\n",
    "sink my $conf51-codex-mini = llm-configuration('ChatGPT', path => 'responses', model => 'gpt-5.1-codex-mini');\n",
    "sink my $conf-gemini20-flash = llm-configuration('Gemini', model => 'gemini-2.0-flash');\n",
    "sink my $conf-gemini25-flash = llm-configuration('Gemini', model => 'gemini-2.5-flash');\n",
    "sink my $conf-gemini25-pro = llm-configuration('Gemini', model => 'gemini-2.5-pro');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe99c4a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Three DSL translations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f090d7e",
   "metadata": {},
   "source": [
    "This section demonstrates the use of tree different translation methods:\n",
    "\n",
    "1. Grammar-based parser-interpreter of computational workflows\n",
    "2. LLM-based translator using few-shot learning with relevant DSL examples\n",
    "3. Natural Language Processing interpreter using code templates and LLMs to fill-in the corresponding parameters\n",
    "\n",
    "The translators are ordered according of their faithfulness, most faithful first. \n",
    "It can be said that at the same time, the translators are ordered according to their coverage -- widest coverage is by the last."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c640bb",
   "metadata": {},
   "source": [
    "### Grammar-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9402835",
   "metadata": {},
   "source": [
    "Here a recommender pipeline specified with natural language commands is translated into Raku code of the package [\"ML::SparseMatrixRecommender\"](https://raku.land/zef:antononcube/ML::SparseMatrixRecommender) using a sub of the package [ \"DSL::Translators\"](https://github.com/antononcube/Raku-DSL-Translators):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "510c44f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my $obj = ML::SparseMatrixRecommender\n",
       ".new\n",
       ".create-from-wide-form(@dsData)\n",
       ".apply-term-weight-functions(global-weight-func => \"IDF\", local-weight-func => \"None\", normalizer-func => \"Cosine\")\n",
       ".recommend-by-profile([\"passengerSex:male\", \"passengerClass:1st\"])\n",
       ".join-across(@dsData, on => \"id\" )\n",
       ".echo-value()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\n",
    "create from @dsData; \n",
    "apply LSI functions IDF, None, Cosine; \n",
    "recommend by profile for passengerSex:male, and passengerClass:1st;\n",
    "join across with @dsData on \"id\";\n",
    "echo the pipeline value\n",
    "'\n",
    "==> ToDSLCode(to => 'Raku', format => 'CODE')\n",
    "==> {.subst('.', \"\\n.\"):g}()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0ada6",
   "metadata": {},
   "source": [
    "For more details of the grammar-based approach see the presentations:\n",
    "- [\"Raku for Prediction presentation at The Raku Conference 2021\"](https://www.youtube.com/watch?v=flPz4lFyn8M)\n",
    "- [\"Simplified Machine Learning Workflows Overview (Raku-centric)\"](https://www.youtube.com/watch?v=p3iwPsc6e74)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e7e2b",
   "metadata": {},
   "source": [
    "### Via LLM examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe272bc",
   "metadata": {},
   "source": [
    "LLM translations can be done using a set of from-to rules. This is the so called *few shot learning* of LLMs. The package [\"DSL::Examples\"](https://raku.land/zef:antononcube/DSL::Examples) has a collection of such examples for different computational workflows. (Mostly ML at this point.) The examples are hierarchically organized by programming language and workflow name; see the resource file [\"dsl-examples.json\"](https://github.com/antononcube/Raku-DSL-Examples/blob/main/resources/dsl-examples.json), execute `dsl-examples`.\n",
    "\n",
    "Here is a table that shows the known DSL translation examples in [\"DSL::Examples\"](https://raku.land/zef:antononcube/DSL::Examples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73938735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><thead><tr><th>language</th><th>workflow</th><th>examples-count</th></tr></thead><tbody><tr><td>Python</td><td>LSAMon</td><td>15</td></tr><tr><td>Python</td><td>QRMon</td><td>23</td></tr><tr><td>Python</td><td>SMRMon</td><td>20</td></tr><tr><td>R</td><td>LSAMon</td><td>17</td></tr><tr><td>R</td><td>QRMon</td><td>26</td></tr><tr><td>R</td><td>SMRMon</td><td>20</td></tr><tr><td>Raku</td><td>SMRMon</td><td>20</td></tr><tr><td>WL</td><td>ClCon</td><td>20</td></tr><tr><td>WL</td><td>LSAMon</td><td>17</td></tr><tr><td>WL</td><td>QRMon</td><td>27</td></tr><tr><td>WL</td><td>SMRMon</td><td>20</td></tr></tbody></table>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "dsl-examples().map({ $_.key X ($_.value.keys Z $_.value.values».elems) }).flat(1).map({ <language workflow examples-count> Z=> $_.flat })».Hash.sort(*<language workflow>).Array\n",
    "==> to-dataset()\n",
    "==> to-html(field-names => <language workflow examples-count>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb91ed5",
   "metadata": {},
   "source": [
    "Here is the definition of an LLM translation function that uses examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34a36776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Function(-> **@args, *%args { #`(Block|4277107090152) ... }, 'chatgpt')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my &llm-pipeline-segment = llm-example-function(dsl-examples()<Raku><SMRMon>);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faecf239",
   "metadata": {},
   "source": [
    "Here is a recommender pipeline specified with natural language commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc28f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "my $spec = q:to/END/;\n",
    "new recommender;\n",
    "create from @dsData; \n",
    "apply LSI functions IDF, None, Cosine; \n",
    "recommend by profile for passengerSex:male, and passengerClass:1st;\n",
    "join across with @dsData on \"id\";\n",
    "echo the pipeline value;\n",
    "classify by profile passengerSex:female, and passengerClass:1st on the tag passengerSurvival;\n",
    "echo value\n",
    "END\n",
    "\n",
    "sink my @commands = $spec.lines;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cea965",
   "metadata": {},
   "source": [
    "Translate to Raku code line-by-line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a38fc3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ML::SparseMatrixRecommender.new;\n",
       ".create(@dsData)\n",
       ".apply-term-weight-functions('IDF', 'None', 'Cosine')\n",
       ".recommend-by-profile({'passengerSex.male' => 1, 'passengerClass.1st' => 1})\n",
       ".join-across(@dsData, on => 'id')\n",
       ".echo-value()\n",
       ".classify-by-profile('passengerSurvival', {'passengerSex.female' => True, 'passengerClass.1st' => True})\n",
       ".echo-value()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@commands\n",
    ".map({ .&llm-pipeline-segment })\n",
    ".map({ .subst(/:i Output \\h* ':'?/, :g).trim })\n",
    ".join(\"\\n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010b8d0",
   "metadata": {},
   "source": [
    "Or translate by just calling the function over the whole `$spec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "661c6779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ML::SparseMatrixRecommender.new;  \n",
       "create(@dsData);  \n",
       "apply-term-weight-functions('IDF', 'None', 'Cosine');  \n",
       "recommend-by-profile({'passengerSex.male' => 1, 'passengerClass.1st' => 1});  \n",
       "join-across(@dsData, on => 'id');  \n",
       "echo-value();  \n",
       "classify-by-profile('passengerSurvival', [{'passengerSex.female' => 1, 'passengerClass.1st' => 1}]);  \n",
       "echo-value()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "&llm-pipeline-segment($spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd59a7f5",
   "metadata": {},
   "source": [
    "**Remark:** That latter call is faster, but it needs additional processing for \"monadic\" workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72111ac",
   "metadata": {},
   "source": [
    "### By NLP Template Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb0887",
   "metadata": {},
   "source": [
    "Here the \"free text\" recommender pipeline specification is translated to Raku code using the sub `concretize` of the package [\"ML::NLPTemplateEngine\"](https://raku.land/zef:antononcube/ML::NLPTemplateEngine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54fd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my $smrObj = ML::SparseMatrixRecommender.new\n",
       ".create-from-wide-form(dfTitanic, item-column-name='id', :add-tag-types-to-column-names, tag-value-separator=':')\n",
       ".apply-term-weight-functions('IDF', 'None', 'Cosine')\n",
       ".recommend-by-profile([\"1st\"], 12, :!normalize)\n",
       ".join-across(dfTitanic)\n",
       ".echo-value();"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'create a recommender with dfTitanic; apply the LSI functions IDF, None, Cosine; recommend by profile 1st and male'\n",
    "==> concretize(lang => \"Raku\", e => $conf41-mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a9992",
   "metadata": {},
   "source": [
    "The package [\"ML::NLPTemplateEngine\"](https://raku.land/zef:antononcube/ML::NLPTemplateEngine) uses a Question Answering System (QAS) implemented in [\"ML::FindTextualAnswer\"](https://raku.land/zef:antononcube/ML::FindTextualAnswer). QAS can be implemented in different ways, with different conceptual and computation complexity. Currently, \"ML::FindTextualAnswer\" has only an LLM based implementation of QAS.\n",
    "\n",
    "For more details of the NLP template engine approach see the presentations:\n",
    "\n",
    "- [\"NLP Template Engine, Part 1\"](https://www.youtube.com/watch?v=a6PvmZnvF9I)\n",
    "- [\"Natural Language Processing Template Engine\"](https://www.youtube.com/watch?v=IrIW9dB5sRM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c1209",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Parallel race: Grammar + LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3921dffa",
   "metadata": {},
   "source": [
    "In this section we implement the first, most obvious, and conceptually simplest combination of grammar-based- with LLM-based translations:\n",
    "\n",
    "- All translators -- grammar-based and LLM-based are run in parallel \n",
    "- An LLM judges selects the one that best adhering to the given specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b292c",
   "metadata": {},
   "source": [
    "The implementation of this strategy with an LLM graph (say, by using [\"LLM::Graph\"](https://raku.land/zef:antononcube/LLM::Graph)) is straightforward.\n",
    "\n",
    "Here is such a LLM graph that:\n",
    "- Tries all three translation methods above\n",
    "- If the DSL grammar-based method does not work then the LLM-based ones are tried\n",
    "- The LLM methods are tried in parallel\n",
    "- There is a judge that picks which on of the LLM methods produced better result\n",
    "- Judge's output is used to make a Markdown report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02d327d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 5, nodes => dsl-grammar, judge, llm-examples, nlp-template-engine, report)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my %rules =\n",
    "    dsl-grammar => { \n",
    "        eval-function => sub ($spec, $lang = 'Raku') { ToDSLCode($spec, to => $lang, format => 'CODE') }\n",
    "    },\n",
    "\n",
    "    llm-examples => { \n",
    "        llm-function => \n",
    "            sub ($spec, $lang = 'Raku', $split = False) { \n",
    "                my &llm-pipeline-segment = llm-example-function(dsl-examples(){$lang}<SMRMon>);\n",
    "                return do if $split {\n",
    "                    note 'with spec splitting...';\n",
    "                    my @commands = $spec.lines;\n",
    "                    @commands.map({ .&llm-pipeline-segment }).map({ .subst(/:i Output \\h* ':'?/, :g).trim }).join(\"\\n.\")\n",
    "                } else {\n",
    "                    note 'no spec splitting...';\n",
    "                    &llm-pipeline-segment($spec).subst(\";\\n\", \"\\n.\"):g\n",
    "                }\n",
    "            },\n",
    "    },\n",
    "\n",
    "    nlp-template-engine => {\n",
    "        llm-function => sub ($spec, $lang = 'Raku') { concretize($spec, :$lang) }\n",
    "    },\n",
    "\n",
    "    judge => sub ($spec, $lang, $dsl-grammar, $llm-examples, $nlp-template-engine) {\n",
    "            [\n",
    "                \"Choose the generated code that most fully adheres to the spec:\\n\",\n",
    "                $spec,\n",
    "                \"\\nfrom the following $lang generation results:\\n\\n\",\n",
    "                \"1) DSL-grammar:\\n$dsl-grammar\\n\",\n",
    "                \"2) LLM-examples:\\n$llm-examples\\n\",\n",
    "                \"3) NLP-template-engine:\\n$nlp-template-engine\\n\",\n",
    "                \"and copy it:\"\n",
    "            ].join(\"\\n\\n\")\n",
    "    },\n",
    "    \n",
    "    report => {\n",
    "            eval-function => sub ($spec, $lang, $dsl-grammar, $llm-examples, $nlp-template-engine, $judge) {\n",
    "                [\n",
    "                    '# Best generated code',\n",
    "                    \"Three $lang code generations were submitted for the spec:\",\n",
    "                    '```text',\n",
    "                    $spec,\n",
    "                    '```',\n",
    "                    'Here are the results:',\n",
    "                    to-html( ['dsl-grammar', 'llm-examples', 'nlp-template-engine'].map({ [ name => $_, code => ::('$' ~ $_)] })».Hash.Array, field-names => <name code> ).subst(\"\\n\", '<br/>'):g,\n",
    "                    '## Judgement',\n",
    "                    $judge.contains('```') ?? $judge !! \"```$lang\\n\" ~ $judge ~ \"\\n```\"\n",
    "                ].join(\"\\n\\n\")\n",
    "            }\n",
    "    }        \n",
    ";\n",
    "\n",
    "my $gBestCode = LLM::Graph.new(%rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed3c694",
   "metadata": {},
   "source": [
    "Here is a recommender workflow specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27c08e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "with spec splitting...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 5, nodes => dsl-grammar, judge, llm-examples, nlp-template-engine, report)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $spec = q:to/END/;\n",
    "make a brand new recommender with the data @dsData;\n",
    "apply LSI functions IDF, None, Cosine; \n",
    "recommend by profile for passengerSex:male, and passengerClass:1st;\n",
    "join across with @dsData on \"id\";\n",
    "echo the pipeline value;\n",
    "END\n",
    "\n",
    "$gBestCode.eval(:$spec, lang => 'Raku', :split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbd87d",
   "metadata": {},
   "source": [
    "Here the LLM-graph result -- which is a Markdown report -- is rendered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30b38797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Best generated code\n",
       "\n",
       "Three Raku code generations were submitted for the spec:\n",
       "\n",
       "```text\n",
       "\n",
       "make a brand new recommender with the data @dsData;\n",
       "apply LSI functions IDF, None, Cosine; \n",
       "recommend by profile for passengerSex:male, and passengerClass:1st;\n",
       "join across with @dsData on \"id\";\n",
       "echo the pipeline value;\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "Here are the results:\n",
       "\n",
       "<table border=\"1\"><thead><tr><th>name</th><th>code</th></tr></thead><tbody><tr><td>dsl-grammar</td><td></td></tr><tr><td>llm-examples</td><td>ML::SparseMatrixRecommender.new(@dsData)<br/>.apply-term-weight-functions(&#39;IDF&#39;, &#39;None&#39;, &#39;Cosine&#39;)<br/>.recommend-by-profile({&#39;passengerSex.male&#39; =&gt; 1, &#39;passengerClass.1st&#39; =&gt; 1})<br/>.join-across(@dsData, on =&gt; &#39;id&#39;)<br/>.echo-value()</td></tr><tr><td>nlp-template-engine</td><td>my $smrObj = ML::SparseMatrixRecommender.new<br/>.create-from-wide-form([&quot;passengerSex:male&quot;, &quot;passengerClass:1st&quot;]set, item-column-name=&#39;id&#39;, :add-tag-types-to-column-names, tag-value-separator=&#39;:&#39;)<br/>.apply-term-weight-functions(&#39;IDF&#39;, &#39;None&#39;, &#39;Cosine&#39;)<br/>.recommend-by-profile([&quot;passengerSex:male&quot;, &quot;passengerClass:1st&quot;], 12, :!normalize)<br/>.join-across([&quot;passengerSex:male&quot;, &quot;passengerClass:1st&quot;]set)<br/>.echo-value();</td></tr></tbody></table>\n",
       "\n",
       "## Judgement\n",
       "\n",
       "```Raku\n",
       "ML::SparseMatrixRecommender.new(@dsData)\n",
       ".apply-term-weight-functions('IDF', 'None', 'Cosine')\n",
       ".recommend-by-profile({'passengerSex.male' => 1, 'passengerClass.1st' => 1})\n",
       ".join-across(@dsData, on => 'id')\n",
       ".echo-value()\n",
       "```"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% markdown\n",
    "$gBestCode.nodes<report><result>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdb65c",
   "metadata": {},
   "source": [
    "### LLM-graph visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3074568",
   "metadata": {},
   "source": [
    "Here is a visualization of the LLM graph defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe181cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.0 (20250921.2048)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"648pt\" height=\"258pt\"\n",
       " viewBox=\"0.00 0.00 648.00 258.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1.27614 1.27614) rotate(0) translate(4 198.4)\">\n",
       "<polygon fill=\"none\" stroke=\"none\" points=\"-4,4 -4,-198.4 503.78,-198.4 503.78,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>judge_Cluster</title>\n",
       "<polygon fill=\"none\" stroke=\"grey\" stroke-dasharray=\"5,2\" points=\"136.45,-49.6 136.45,-87.2 274.45,-87.2 274.45,-49.6 136.45,-49.6\"/>\n",
       "</g>\n",
       "<!-- dsl&#45;grammar -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>dsl&#45;grammar</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"470.65,-136.8 348.25,-136.8 348.25,-115.2 470.65,-115.2 470.65,-136.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"409.45\" y=\"-121.72\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">dsl&#45;grammar</text>\n",
       "</g>\n",
       "<!-- judge -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>judge</title>\n",
       "<ellipse fill=\"SteelBlue\" stroke=\"grey\" cx=\"205.45\" cy=\"-68.4\" rx=\"61.2\" ry=\"10.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"205.45\" y=\"-64.12\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">judge</text>\n",
       "</g>\n",
       "<!-- dsl&#45;grammar&#45;&gt;judge -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>dsl&#45;grammar&#45;&gt;judge</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M372.03,-114.8C336.71,-105.17 283.82,-90.76 247.15,-80.77\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"248.42,-77.48 237.85,-78.23 246.58,-84.24 248.42,-77.48\"/>\n",
       "</g>\n",
       "<!-- report -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>report</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"310.65,-21.6 188.25,-21.6 188.25,0 310.65,0 310.65,-21.6\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"249.45\" y=\"-6.52\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">report</text>\n",
       "</g>\n",
       "<!-- dsl&#45;grammar&#45;&gt;report -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>dsl&#45;grammar&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M394.97,-114.75C367.12,-95.05 305.92,-51.75 272.44,-28.07\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"274.46,-25.21 264.28,-22.29 270.42,-30.92 274.46,-25.21\"/>\n",
       "</g>\n",
       "<!-- judge&#45;&gt;report -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>judge&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M213.52,-57.2C219.54,-49.6 227.91,-39.01 235.07,-29.98\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"237.59,-32.42 241.05,-22.41 232.1,-28.08 237.59,-32.42\"/>\n",
       "</g>\n",
       "<!-- lang -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>lang</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"271.9,-194.4 170.96,-194.4 145,-172.8 245.93,-172.8 271.9,-194.4\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"208.45\" y=\"-179.32\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">lang</text>\n",
       "</g>\n",
       "<!-- lang&#45;&gt;dsl&#45;grammar -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>lang&#45;&gt;dsl&#45;grammar</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M245.32,-172.4C278.22,-163.3 326.59,-149.92 362.3,-140.04\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"363.19,-143.43 371.89,-137.39 361.32,-136.68 363.19,-143.43\"/>\n",
       "</g>\n",
       "<!-- lang&#45;&gt;judge -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>lang&#45;&gt;judge</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M205.88,-172.5C203.67,-163.27 200.66,-149.22 199.45,-136.8 197.92,-121.06 199.65,-103.25 201.65,-89.88\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"205.09,-90.49 203.29,-80.05 198.19,-89.34 205.09,-90.49\"/>\n",
       "</g>\n",
       "<!-- llm&#45;examples -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>llm&#45;examples</title>\n",
       "<ellipse fill=\"SteelBlue\" stroke=\"grey\" cx=\"91.45\" cy=\"-126\" rx=\"61.2\" ry=\"10.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"91.45\" y=\"-121.72\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">llm&#45;examples</text>\n",
       "</g>\n",
       "<!-- lang&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>lang&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M186.99,-172.4C168.51,-163.62 141.65,-150.85 121.11,-141.09\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"122.68,-137.97 112.15,-136.84 119.68,-144.29 122.68,-137.97\"/>\n",
       "</g>\n",
       "<!-- nlp&#45;template&#45;engine -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>nlp&#45;template&#45;engine</title>\n",
       "<ellipse fill=\"SteelBlue\" stroke=\"grey\" cx=\"269.45\" cy=\"-126\" rx=\"61.2\" ry=\"10.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"269.45\" y=\"-121.72\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">nlp&#45;template&#45;engine</text>\n",
       "</g>\n",
       "<!-- lang&#45;&gt;nlp&#45;template&#45;engine -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>lang&#45;&gt;nlp&#45;template&#45;engine</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M219.64,-172.4C228.43,-164.39 240.86,-153.06 251.11,-143.72\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"253.26,-146.49 258.29,-137.17 248.55,-141.32 253.26,-146.49\"/>\n",
       "</g>\n",
       "<!-- lang&#45;&gt;report -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>lang&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M151.78,-172.36C99.8,-162.39 29.65,-147.25 21.45,-136.8 15.52,-129.25 17.34,-123.88 21.45,-115.2 49.15,-56.67 121.82,-31.25 177.74,-20.22\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"178.19,-23.69 187.38,-18.43 176.91,-16.81 178.19,-23.69\"/>\n",
       "</g>\n",
       "<!-- llm&#45;examples&#45;&gt;judge -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>llm&#45;examples&#45;&gt;judge</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M111.31,-115.32C129.29,-106.55 156,-93.52 176.39,-83.57\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"177.82,-86.77 185.28,-79.24 174.75,-80.48 177.82,-86.77\"/>\n",
       "</g>\n",
       "<!-- llm&#45;examples&#45;&gt;report -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>llm&#45;examples&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M94.27,-114.88C99.27,-98.74 111.24,-67.2 132.45,-49.6 145.84,-38.49 162.56,-30.62 179.14,-25.06\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"179.76,-28.53 188.28,-22.22 177.69,-21.85 179.76,-28.53\"/>\n",
       "</g>\n",
       "<!-- nlp&#45;template&#45;engine&#45;&gt;judge -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>nlp&#45;template&#45;engine&#45;&gt;judge</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M258.01,-115.06C248.72,-107 235.44,-95.45 224.55,-85.99\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"227.09,-83.57 217.25,-79.65 222.5,-88.85 227.09,-83.57\"/>\n",
       "</g>\n",
       "<!-- nlp&#45;template&#45;engine&#45;&gt;report -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>nlp&#45;template&#45;engine&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M273.37,-114.95C278.53,-100.22 286.08,-72.07 278.45,-49.6 276.02,-42.44 271.63,-35.58 266.99,-29.71\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"269.81,-27.62 260.61,-22.37 264.52,-32.21 269.81,-27.62\"/>\n",
       "</g>\n",
       "<!-- spec -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>spec</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"472.9,-194.4 371.96,-194.4 346,-172.8 446.93,-172.8 472.9,-194.4\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"409.45\" y=\"-179.32\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">spec</text>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;dsl&#45;grammar -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>spec&#45;&gt;dsl&#45;grammar</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M409.45,-172.4C409.45,-165.51 409.45,-156.15 409.45,-147.73\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"412.95,-147.74 409.45,-137.74 405.95,-147.74 412.95,-147.74\"/>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;judge -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>spec&#45;&gt;judge</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M434.12,-172.3C461.03,-159.63 497.98,-137.09 479.45,-115.2 453.87,-84.99 348.41,-74.69 276.04,-71.19\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"276.37,-67.7 266.22,-70.75 276.06,-74.69 276.37,-67.7\"/>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>spec&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M350.75,-172.34C291.28,-161.94 200.17,-146.01 143.29,-136.06\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"144.13,-132.66 133.68,-134.38 142.93,-139.55 144.13,-132.66\"/>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;nlp&#45;template&#45;engine -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>spec&#45;&gt;nlp&#45;template&#45;engine</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M383.77,-172.4C361.01,-163.36 327.64,-150.11 302.82,-140.25\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"304.25,-137.05 293.66,-136.62 301.66,-143.56 304.25,-137.05\"/>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;report -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>spec&#45;&gt;report</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M442.55,-172.4C473.41,-161.05 512.33,-140.88 495.45,-115.2 457.21,-57.05 379.13,-31.54 321.15,-20.39\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"321.99,-16.98 311.53,-18.64 320.74,-23.87 321.99,-16.98\"/>\n",
       "</g>\n",
       "<!-- split -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>split</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"126.9,-194.4 25.96,-194.4 0,-172.8 100.93,-172.8 126.9,-194.4\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"63.45\" y=\"-179.32\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">split</text>\n",
       "</g>\n",
       "<!-- split&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>split&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M68.58,-172.4C72.22,-165.19 77.2,-155.3 81.59,-146.59\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"84.7,-148.18 86.07,-137.67 78.45,-145.03 84.7,-148.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "$gBestCode.dot(engine => 'dot', :9graph-size, node-width => 1.7, node-color => 'grey', edge-color => 'grey', edge-width => 0.4, theme => 'default'):svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886efb24",
   "metadata": {},
   "source": [
    "For details on LLM-graphs making and their visualization representations see blog posts:\n",
    "\n",
    "- [\"LLM::Graph\"](https://rakuforprediction.wordpress.com/2025/08/23/llmgraph/)\n",
    "- [\"LLM::Graph plots interpretation guide\"](https://rakuforprediction.wordpress.com/2025/09/12/llmgraph-plots-interpretation-guide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59575620",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fallback: DSL-grammar to LLM-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49fe94",
   "metadata": {},
   "source": [
    "Instead of having DSL-grammar and LLM computations running in parallel, we can make LLM-graph in which the LLM computations are invoked if the DSL-grammar parsing-and-interpretation fails. In this section we make such a graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e8a4bd",
   "metadata": {},
   "source": [
    "Before making the graph let us also generalize it to work with other Machine Learning workflows, not just recommendations. The function `ToDSLCode` (of the package \"DSL::Translators\") has an ML workflow classifier (based on prefix trees.) \n",
    "\n",
    "Let us make an LLM function with a similar functionality. I.e. an LLM-function that classifies a natural language computation specification into workflow labels used by \"DSL::Examples\". Here is such a function using the `llm-classify` provided by [\"ML::FindTextualAnswer\"](https://raku.land/zef:antononcube/ML::FindTextualAnswer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b554bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot convert from JSON, returning \"asis\".\n",
      "Cannot deterimine the class label.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Failed to resolve host name 'api.openai.com' with family 0.\n",
       "Error: nodename nor servname provided, or not known"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Natural language labels to be understood by LLMs\n",
    "my @mlLabels = 'Classification', 'Latent Semantic Analysis', 'Quantile Regression', 'Recommendations';\n",
    "\n",
    "# Map natural language labels to workflow names in \"DSL::Examples\"\n",
    "my %toMonNames = @mlLabels Z=> <ClCon LSAMon QRMon SMRMon>; \n",
    "\n",
    "# Change the result of &llm-classify result into workflow names\n",
    "my &llm-ml-workflow = -> $spec { my $res = llm-classify($spec, @mlLabels, request => 'which of these workflows characterizes it'); %toMonNames{$res} // $res };\n",
    "\n",
    "# Example invocation\n",
    "&llm-ml-workflow($spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cb4d6",
   "metadata": {},
   "source": [
    "In addition, we have to specify a pipeline \"separator\" for the different programming languages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "033aed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my %langSeparator = Python => \"\\n.\", Raku => \"\\n.\", R => \"%>%\\n\", WL => \"⟹\\n\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c0e8a",
   "metadata": {},
   "source": [
    "Here is the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd6cb760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 4, nodes => code, dsl-grammar, llm-examples, workflow-name)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my %rules =\n",
    "    dsl-grammar => { \n",
    "        eval-function => sub ($spec, $lang = 'Raku') { \n",
    "            my $res = ToDSLCode($spec, to => $lang, format => 'CODE'); \n",
    "            my $checkStr = 'my $obj = ML::SparseMatrixRecommender.new';\n",
    "            return do with $res.match(/ $checkStr /):g { \n",
    "                $/.list.elems > 1 ?? $res.subst($checkStr) !! $res \n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    workflow-name => {\n",
    "        llm-function => sub ($spec) { &llm-ml-workflow($spec) }\n",
    "    },\n",
    "\n",
    "    llm-examples => { \n",
    "        llm-function => \n",
    "            sub ($spec, $workflow-name, $lang = 'Raku', $split = False) {\n",
    "                my &llm-pipeline-segment = llm-example-function(dsl-examples(){$lang}{$workflow-name});\n",
    "                return do if $split {\n",
    "                    my @commands = $spec.lines;\n",
    "                    @commands.map({ .&llm-pipeline-segment }).map({ .subst(/:i Output \\h* ':'?/, :g).trim }).join(%langSeparator{$lang})\n",
    "                } else {\n",
    "                    &llm-pipeline-segment($spec).subst(\";\\n\", %langSeparator{$lang}):g\n",
    "                }\n",
    "            },\n",
    "        test-function => sub ($dsl-grammar) { !($dsl-grammar ~~ Str:D && $dsl-grammar.trim.chars) }\n",
    "    },\n",
    "    \n",
    "    code => {\n",
    "            eval-function => sub ($dsl-grammar, $llm-examples) {\n",
    "                $dsl-grammar ~~ Str:D && $dsl-grammar.trim ?? $dsl-grammar !! $llm-examples\n",
    "            }\n",
    "    }   \n",
    ";\n",
    "\n",
    "my $gRobust = LLM::Graph.new(%rules):!async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0ac3c",
   "metadata": {},
   "source": [
    "Here the LLM graph run over a spec that can be parsed by DSL-grammar (notice the very short computation time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556b1e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 4, nodes => code, dsl-grammar, llm-examples, workflow-name)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $spec = q:to/END/;\n",
    "create from @dsData; \n",
    "apply LSI functions IDF, None, Cosine; \n",
    "recommend by profile for passengerSex:male, and passengerClass:1st;\n",
    "join across with @dsData on \"id\";\n",
    "echo the pipeline value;\n",
    "END\n",
    "\n",
    "$gRobust.eval(:$spec, lang => 'Raku', :!split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5141df",
   "metadata": {},
   "source": [
    "Here is the obtained result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97a43821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my $obj = ML::SparseMatrixRecommender.new.create-from-wide-form(@dsData).apply-term-weight-functions(global-weight-func => \"IDF\", local-weight-func => \"None\", normalizer-func => \"Cosine\").recommend-by-profile([\"passengerSex:male\", \"passengerClass:1st\"]).join-across(@dsData, on => \"id\" ).echo-value()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$gRobust.nodes<code><result>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f912691",
   "metadata": {},
   "source": [
    "Here is a spec that cannot be parsed by DSL-grammar interpreter -- note there is just a small language change in the first line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cae8326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot parse the command; error in rule recommender-object-phrase:sym<English> at line 1; target 'new recommender with @dsData, please' position 16; parsed 'new recommender', un-parsed 'with @dsData, please' .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 4, nodes => code, dsl-grammar, llm-examples, workflow-name)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $spec = q:to/END/;\n",
    "new recommender with @dsData, please; \n",
    "also apply LSI functions IDF, None, Cosine; \n",
    "recommend by profile for passengerSex:male, and passengerClass:1st;\n",
    "join across with @dsData on \"id\";\n",
    "echo the pipeline value;\n",
    "END\n",
    "\n",
    "$gRobust.eval(:$spec, lang => 'Raku', :!split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40adc493",
   "metadata": {},
   "source": [
    "Nevertheless, we obtain a correct result via LLM-examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dff9eeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ML::SparseMatrixRecommender.new(@dsData)\n",
       ".apply-term-weight-functions('IDF', 'None', 'Cosine')\n",
       ".recommend-by-profile({'passengerSex.male' => 1, 'passengerClass.1st' => 1})\n",
       ".join-across(@dsData, on => 'id')\n",
       ".echo-value();"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$gRobust.nodes<code><result>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c594118",
   "metadata": {},
   "source": [
    "Here is the corresponding graph plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f90739f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.0 (20250921.2048)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"648pt\" height=\"248pt\"\n",
       " viewBox=\"0.00 0.00 648.00 248.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1.22751 1.22751) rotate(0) translate(4 198.4)\">\n",
       "<polygon fill=\"none\" stroke=\"none\" points=\"-4,4 -4,-198.4 523.9,-198.4 523.9,4 -4,4\"/>\n",
       "<!-- code -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>code</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"400.65,-21.6 278.25,-21.6 278.25,0 400.65,0 400.65,-21.6\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"339.45\" y=\"-6.52\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">code</text>\n",
       "</g>\n",
       "<!-- dsl&#45;grammar -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>dsl&#45;grammar</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"445.65,-136.8 323.25,-136.8 323.25,-115.2 445.65,-115.2 445.65,-136.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"384.45\" y=\"-121.72\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">dsl&#45;grammar</text>\n",
       "</g>\n",
       "<!-- dsl&#45;grammar&#45;&gt;code -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>dsl&#45;grammar&#45;&gt;code</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M382.46,-115.15C379.58,-101.8 373.69,-77.34 365.45,-57.6 361.64,-48.48 356.42,-38.9 351.65,-30.87\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"354.72,-29.19 346.5,-22.5 348.76,-32.85 354.72,-29.19\"/>\n",
       "</g>\n",
       "<!-- llm&#45;examples -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>llm&#45;examples</title>\n",
       "<ellipse fill=\"SteelBlue\" stroke=\"grey\" cx=\"295.45\" cy=\"-68.4\" rx=\"61.2\" ry=\"10.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"295.45\" y=\"-64.12\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">llm&#45;examples</text>\n",
       "</g>\n",
       "<!-- dsl&#45;grammar&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>dsl&#45;grammar&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" stroke-dasharray=\"5,2\" d=\"M368.13,-114.8C354.66,-106.39 335.35,-94.33 320.02,-84.75\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"321.92,-81.81 311.59,-79.48 318.21,-87.75 321.92,-81.81\"/>\n",
       "</g>\n",
       "<!-- lang -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>lang</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"519.9,-194.4 418.96,-194.4 393,-172.8 493.93,-172.8 519.9,-194.4\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"456.45\" y=\"-179.32\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">lang</text>\n",
       "</g>\n",
       "<!-- lang&#45;&gt;dsl&#45;grammar -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>lang&#45;&gt;dsl&#45;grammar</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M443.24,-172.4C432.79,-164.33 417.98,-152.89 405.84,-143.52\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"408.1,-140.85 398.05,-137.5 403.83,-146.39 408.1,-140.85\"/>\n",
       "</g>\n",
       "<!-- lang&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>lang&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M459.44,-172.71C463.11,-158.41 467.37,-131.85 454.45,-115.2 441.49,-98.5 390.87,-85.86 350.18,-78.14\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"350.88,-74.71 340.41,-76.34 349.61,-81.59 350.88,-74.71\"/>\n",
       "</g>\n",
       "<!-- llm&#45;examples&#45;&gt;code -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>llm&#45;examples&#45;&gt;code</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M303.52,-57.2C309.54,-49.6 317.91,-39.01 325.07,-29.98\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"327.59,-32.42 331.05,-22.41 322.1,-28.08 327.59,-32.42\"/>\n",
       "</g>\n",
       "<!-- spec -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>spec</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"358.9,-194.4 257.96,-194.4 232,-172.8 332.93,-172.8 358.9,-194.4\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"295.45\" y=\"-179.32\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">spec</text>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;dsl&#45;grammar -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>spec&#45;&gt;dsl&#45;grammar</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M311.77,-172.4C325.07,-164.09 344.07,-152.22 359.31,-142.7\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"361.09,-145.72 367.72,-137.45 357.38,-139.78 361.09,-145.72\"/>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>spec&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M295.45,-172.55C295.45,-154.06 295.45,-114.27 295.45,-89.87\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"298.95,-90.19 295.45,-80.19 291.95,-90.19 298.95,-90.19\"/>\n",
       "</g>\n",
       "<!-- workflow&#45;name -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>workflow&#45;name</title>\n",
       "<ellipse fill=\"SteelBlue\" stroke=\"grey\" cx=\"206.45\" cy=\"-126\" rx=\"61.2\" ry=\"10.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"206.45\" y=\"-121.72\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">workflow&#45;name</text>\n",
       "</g>\n",
       "<!-- spec&#45;&gt;workflow&#45;name -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>spec&#45;&gt;workflow&#45;name</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M279.13,-172.4C265.66,-163.99 246.35,-151.93 231.02,-142.35\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"232.92,-139.41 222.59,-137.08 229.21,-145.35 232.92,-139.41\"/>\n",
       "</g>\n",
       "<!-- split -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>split</title>\n",
       "<polygon fill=\"SteelBlue\" stroke=\"grey\" points=\"126.9,-136.8 25.96,-136.8 0,-115.2 100.93,-115.2 126.9,-136.8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"63.45\" y=\"-121.72\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"White\">split</text>\n",
       "</g>\n",
       "<!-- split&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>split&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M102.28,-115.69C143.27,-105.87 207.8,-90.41 250.85,-80.09\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"251.54,-83.52 260.45,-77.79 249.91,-76.72 251.54,-83.52\"/>\n",
       "</g>\n",
       "<!-- workflow&#45;name&#45;&gt;llm&#45;examples -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>workflow&#45;name&#45;&gt;llm&#45;examples</title>\n",
       "<path fill=\"none\" stroke=\"grey\" stroke-width=\"0.4\" d=\"M221.95,-115.32C235.52,-106.84 255.47,-94.38 271.16,-84.57\"/>\n",
       "<polygon fill=\"grey\" stroke=\"grey\" stroke-width=\"0.4\" points=\"272.69,-87.75 279.31,-79.48 268.98,-81.81 272.69,-87.75\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "$gRobust.dot(engine => 'dot', :9graph-size, node-width => 1.7, node-color => 'grey', edge-color => 'grey', edge-width => 0.4, theme => 'default'):svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04269c24",
   "metadata": {},
   "source": [
    "Let us specify another workflow -- for ML-classification with Wolfram Language -- an run the graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4f7f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 4, nodes => code, dsl-grammar, llm-examples, workflow-name)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $spec = q:to/END/;\n",
    "use the dataset @dsData;\n",
    "split the data into training and testing parts with 0.8 ratio;\n",
    "make a nearest neighbors classifier;\n",
    "show classifier accuracy, precision, and recall;\n",
    "echo the pipeline value;\n",
    "END\n",
    "\n",
    "$gRobust.eval(:$spec, lang => 'WL', :split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "908570eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClConUnit[dsData]⟹\n",
       "ClConSplitData[0.8]⟹\n",
       "ClConMakeClassifier[\"NearestNeighbors\"]⟹\n",
       "Function[{v,c},ClConUnit[v,c]⟹ClConClassifierMeasurements[{\"Accuracy\",\"Precision\",\"Recall\"}]⟹ClConEchoValue]⟹\n",
       "ClConEchoValue"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$gRobust.nodes<code><result>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d6537f",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Concluding comments and observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3bd624",
   "metadata": {},
   "source": [
    "- Using LLM graphs gives the ability to impose desired orchestration and collaboration between deterministic programs and LLMs.\n",
    "\n",
    "    - By contrast, the \"inversion of control\" of LLM-tools makes \"capricious.\"\n",
    "\n",
    "- LLM-graphs are both a generalization of LLM-tools, and a lower level infrastructural functionality than LLM-tools.\n",
    "\n",
    "- The LLM-graph for the parallel-race for translation is very similar to the LLM-graph for comprehensive document summarization described in [AA4].\n",
    "\n",
    "- The expectation that DSL examples would provide both fast and faithful results is mostly confirmed in ≈20 experiments.\n",
    "\n",
    "- Using NLP template engine is also fast because LLMs are harnessed through QAS.\n",
    "\n",
    "- The DSL examples translation had to be completed with a workflow classifier\n",
    "\n",
    "    - Such classifiers are also part of the implementations of the other two approaches.\n",
    "\n",
    "    - The grammar-based one uses a deterministic classifier, [AA1].\n",
    "\n",
    "    - The NLP template engine uses an LLM classifier.\n",
    "\n",
    "- An interesting extension of the current work is to have a grammar-LLM combination in which when the grammar fails whe LLM \"normalizes\" the specs until the grammar can parse them.\n",
    "\n",
    "    - Currently, LLM-graph does not support graphs with cycles, hence this approach \"can wait\" (or be implemented by other means.)\n",
    "\n",
    "- Multiple DSL examples can be efficiently derived by random sentence generation with the different grammars.\n",
    "\n",
    "    - Similar to the DSL commands classifier making approach taken in [AA1].\n",
    "\n",
    "- LLMs can be also used to improve and extend the DSL grammars. \n",
    "\n",
    "    - And it is interesting to consider automating that process, instead of doing it via human supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a3abf",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## References\n",
    "\n",
    "### Articles, blog posts\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"Fast and compact classifier of DSL commands\"](https://rakuforprediction.wordpress.com/2022/07/31/fast-and-compact-classifier-of-dsl-commands/),\n",
    "(2022),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com/).\n",
    "\n",
    "[AA2] Anton Antonov,\n",
    "[\"Grammar based random sentences generation, Part 1\"](https://rakuforprediction.wordpress.com/2023/01/23/grammar-based-random-sentences-generation-part-1/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com/).\n",
    "\n",
    "[AA3] Anton Antonov,\n",
    "[\"LLM::Graph\"](https://rakuforprediction.wordpress.com/2025/08/23/llmgraph/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com/).\n",
    "\n",
    "[AA4] Anton Antonov,\n",
    "[\"Agentic-AI for text summarization\"](https://rakuforprediction.wordpress.com/2025/09/02/agentic-ai-for-text-summarization/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com/).\n",
    "\n",
    "[AA5] Anton Antonov,\n",
    "[\"LLM::Graph plots interpretation guide\"](https://rakuforprediction.wordpress.com/2025/09/12/llmgraph-plots-interpretation-guide/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com/).\n",
    "\n",
    "### Packages\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[DSL::Translators, Raku package](https://github.com/antononcube/Raku-DSL-Translators),\n",
    "(2020-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[ML::FindTextualAnswer, Raku package](https://github.com/antononcube/Raku-ML-FindTextualAnswer/),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[MLP::NLPTemplateEngine, Raku package](https://github.com/antononcube/Raku-ML-NLPTemplateEngine/),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp4] Anton Antonov,\n",
    "[DSL::Examples, Raku package](https://github.com/antononcube/Raku-DSL-Examples),\n",
    "(2024-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp5] Anton Antonov,\n",
    "[LLM::Graph, Raku package](https://github.com/antononcube/Raku-LLM-Graph),\n",
    "(2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp6] Anton Antonov,\n",
    "[ML::SparseMatrixRecommender, Raku package](https://github.com/antononcube/Raku-ML-SparseMatrixRecommender/),\n",
    "(2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "### Videos\n",
    "\n",
    "[AAv1] Anton Antonov,\n",
    "[\"NLP Template Engine, Part 1\"](https://www.youtube.com/watch?v=a6PvmZnvF9I),\n",
    "(2021),\n",
    "[YouTube/@AAA4prediction](https://www.youtube.com/@AAA4prediction).\n",
    "\n",
    "[AAv2] Anton Antonov,\n",
    "[\"Natural Language Processing Template Engine\"](https://www.youtube.com/watch?v=IrIW9dB5sRM),\n",
    "(2023),\n",
    "[YouTube/@WolframResearch](https://www.youtube.com/@WolframResearch).\n",
    "\n",
    "[WRIv1] Wolfram Research, Inc., \n",
    "[“Live CEOing Ep 886: Design Review of LLMGraph”](https://www.youtube.com/watch?v=ewU83vHwN8Y), \n",
    "(2025), \n",
    "[YouTube/@WolframResearch](https://www.youtube.com/@WolframResearch)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943369d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
