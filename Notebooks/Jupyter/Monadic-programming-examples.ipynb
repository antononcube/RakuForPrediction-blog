{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a533624c",
   "metadata": {},
   "source": [
    "# Monadic programming examples\n",
    "\n",
    "Anton Antonov   \n",
    "[MathematicaForPrediction at WordPress](https://mathematicaforprediction.wordpress.com)  \n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com)   \n",
    "November, December 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c0369",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836c02b",
   "metadata": {},
   "source": [
    "This document ([notebook](https://github.com/antononcube/RakuForPrediction-blog/blob/main/Notebooks/Jupyter/Monadic-programming-examples.ipynb)) has example of monadic pipelines for computational workflows in Raku. It is a extend the blog post [\"Monad laws in Raku\"](https://rakuforprediction.wordpress.com/2025/11/16/monad-laws-in-raku/), [AA2], ([notebook](https://github.com/antononcube/RakuForPrediction-blog/blob/main/Notebooks/Jupyter/Monad-laws-in-Raku.ipynb)), with \"real-life\" examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8020808",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "As in mentioned in [AA2], here is a list of the applications of monadic programming we consider:\n",
    "\n",
    "1. Graceful failure handling\n",
    "\n",
    "2. Rapid specification of computational workflows\n",
    "\n",
    "3. Algebraic structure of written code\n",
    "\n",
    "**Remark:** Those applications are discussed in [AAv5] (and its future Raku version.)\n",
    "\n",
    "As [a tools maker for Data Science (DS) and Machine Learning (ML)](https://raku-advent.blog/2025/12/02/day-2-doing-data-science-with-raku/), [AA3], \n",
    "I am very interested in Point 1; but as a \"simple data scientist\" I am mostly interested in Point 2.\n",
    "\n",
    "That said, a large part of my Raku programming has been dedicated to rapid and reliable code generation for DS and ML by leveraging the algebraic structure of corresponding software monads, i.e. Point 3. (See [AAv2, AAv3, AAv4].) For me, first and foremost, ***monadic programming pipelines are just convenient interfaces to computational workflows***. Often I make software packages that allow \"easy\", linear workflows that can have very involved computational steps and multiple tuning options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf21d9",
   "metadata": {},
   "source": [
    "### Dictionary\n",
    "\n",
    "- **Monadic programming**   \n",
    "  A method for organizing computations as a series of steps, where each step generates a value along with additional information about the computation, such as possible failures, non-determinism, or side effects. See [Wk1].\n",
    "\n",
    "- **Monadic pipeline**   \n",
    "  Chaining of operations with a certain syntax. Monad laws apply loosely (or strongly) to that chaining. \n",
    "\n",
    "- **Uniform Function Call Syntax (UFCS)**  \n",
    "  A feature that allows both free functions and member functions to be called using the same `object.function()` method call syntax. \n",
    "\n",
    "- **Method-like call**   \n",
    "  Same as UFCS. A Raku example: `[3, 4, 5].&f1.$f2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d69e189",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324ca61",
   "metadata": {},
   "source": [
    "Here are loaded packages used in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a329504",
   "metadata": {},
   "outputs": [],
   "source": [
    "use Data::Reshapers;\n",
    "use Data::TypeSystem;\n",
    "use Data::Translators;\n",
    "\n",
    "use DSL::Translators;\n",
    "use DSL::Examples;\n",
    "\n",
    "use ML::SparseMatrixRecommender;\n",
    "use ML::TriesWithFrequencies;\n",
    "\n",
    "use Hilite::Simple;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b914d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prefix trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15f4ce",
   "metadata": {},
   "source": [
    "Here is a list of steps:\n",
    "\n",
    "- Make a prefix tree (trie) with frequencies using word splitting over `@words2`\n",
    "- Merge the trie with the another trie made over `@words3`\n",
    "- Convert the node frequencies into probabilities\n",
    "- Shrink the trie (i.e. find the \"prefixes\")\n",
    "- Show the tree-form of the trie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f727027",
   "metadata": {},
   "source": [
    "Let us make a small trie of pet names (used by Raku or Perl fans):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6966eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my @words1 = random-pet-name(*)».lc.grep(/ ^ perl /);\n",
    "sink my @words2 = random-pet-name(*)».lc.grep(/ ^ [ra [k|c] | camel ] /);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb562fb3",
   "metadata": {},
   "source": [
    "Here we make a trie (prefix tree) for those pet names using the feed operator and the functions of [\"ML::TriesWithFrequencies\"](https://raku.land/zef:antononcube/ML::TriesWithFrequencies):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b51f6ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIEROOT => 1\n",
      "├─camel => 0.10526315789473684\n",
      "│ ├─ia => 0.5\n",
      "│ └─o => 0.5\n",
      "├─perl => 0.2631578947368421\n",
      "│ ├─a => 0.2\n",
      "│ ├─e => 0.2\n",
      "│ └─ita => 0.2\n",
      "└─ra => 0.631578947368421\n",
      "  ├─c => 0.75\n",
      "  │ ├─er => 0.2222222222222222\n",
      "  │ ├─he => 0.5555555555555556\n",
      "  │ │ ├─al => 0.2\n",
      "  │ │ └─l => 0.8\n",
      "  │ │   └─  => 0.5\n",
      "  │ │     ├─(ray ray) => 0.5\n",
      "  │ │     └─ray => 0.5\n",
      "  │ ├─ie => 0.1111111111111111\n",
      "  │ └─ket => 0.1111111111111111\n",
      "  └─k => 0.25\n",
      "    ├─i => 0.3333333333333333\n",
      "    └─sha => 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "@words1 ==> \n",
    "trie-create-by-split==>\n",
    "trie-merge(@words2.&trie-create-by-split) ==>\n",
    "trie-node-probabilities==>\n",
    "trie-shrink==>\n",
    "trie-say"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb213ff",
   "metadata": {},
   "source": [
    "Using `andthen` and the `Trie` class methods (but skipping node-probabilities calculation in order to see the counts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "96a78a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRIEROOT => 19\n",
       "├─camel => 2\n",
       "│ ├─ia => 1\n",
       "│ └─o => 1\n",
       "├─perl => 5\n",
       "│ ├─a => 1\n",
       "│ ├─e => 1\n",
       "│ └─ita => 1\n",
       "└─ra => 12\n",
       "  ├─c => 9\n",
       "  │ ├─er => 2\n",
       "  │ ├─he => 5\n",
       "  │ │ ├─al => 1\n",
       "  │ │ └─l => 4\n",
       "  │ │   └─  => 2\n",
       "  │ │     ├─(ray ray) => 1\n",
       "  │ │     └─ray => 1\n",
       "  │ ├─ie => 1\n",
       "  │ └─ket => 1\n",
       "  └─k => 3\n",
       "    ├─i => 1\n",
       "    └─sha => 2"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@words1\n",
    "andthen .&trie-create-by-split\n",
    "andthen .merge( @words2.&trie-create-by-split )\n",
    "# andthen .node-probabilities\n",
    "andthen .shrink\n",
    "andthen .form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2ae5d",
   "metadata": {},
   "source": [
    "---- \n",
    "\n",
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a49001",
   "metadata": {},
   "source": [
    "One appealing way to show that monadic pipelines result in clean and readable code, is to demonstrate their use in Raku through data wrangling operations.\n",
    "Here we load \"data packages\", get the Titanic dataset, show its structure, and show a sample of its rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7c542f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector(Assoc(Atom((Str)), Atom((Str)), 5), 1309)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><thead><tr><th>id</th><th>passengerClass</th><th>passengerSex</th><th>passengerAge</th><th>passengerSurvival</th></tr></thead><tbody><tr><td>904</td><td>3rd</td><td>female</td><td>-1</td><td>died</td></tr><tr><td>285</td><td>1st</td><td>female</td><td>60</td><td>survived</td></tr><tr><td>418</td><td>2nd</td><td>male</td><td>30</td><td>died</td></tr><tr><td>201</td><td>1st</td><td>male</td><td>50</td><td>died</td></tr><tr><td>30</td><td>1st</td><td>male</td><td>30</td><td>survived</td></tr><tr><td>443</td><td>2nd</td><td>male</td><td>20</td><td>died</td></tr></tbody></table>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "my @dsTitanic = get-titanic-dataset();\n",
    "my @field-names = <id passengerClass passengerSex passengerAge passengerSurvival>;\n",
    "\n",
    "say deduce-type(@dsTitanic);\n",
    "\n",
    "@dsTitanic.pick(6) \n",
    "==> to-html(:@field-names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c29ec",
   "metadata": {},
   "source": [
    "Here is an `andthen` data wrangling monadic pipeline, the lines of which have the following interpretations:\n",
    "\n",
    "- Initial pipeline value (the dataset)\n",
    "- Rename columns\n",
    "- Filter rows (with age greater or equal to 10)\n",
    "- Group by the values of the columns \"sex\" and \"survival\"\n",
    "- Show the structure of the pipeline value\n",
    "- Give the sizes of each group as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dff35b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: Struct([female.died, female.survived, male.died, male.survived], [Array, Array, Array, Array])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{female.died => 88, female.survived => 272, male.died => 512, male.survived => 118}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dsTitanic \n",
    "andthen rename-columns($_,  {passengerAge => 'age', passengerSex => 'sex', passengerSurvival => 'survival'})\n",
    "andthen $_.grep(*<age> ≥ 10).List\n",
    "andthen group-by($_, <sex survival>)\n",
    "andthen {say \"Dataset type: \", deduce-type($_); $_}($_)\n",
    "andthen $_».elems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2b91d",
   "metadata": {},
   "source": [
    "**Remark:** The `andthen` pipeline corresponds to the R pipeline in the second section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1639a3",
   "metadata": {},
   "source": [
    "Similar result can be obtained via cross-tabulation and using a pipeline with the feed (`==>`) operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "43979aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+------+----------+\n",
       "|        | died | survived |\n",
       "+--------+------+----------+\n",
       "| female |  88  |   272    |\n",
       "| male   | 512  |   118    |\n",
       "+--------+------+----------+"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dsTitanic\n",
    "==> { .grep(*<passengerAge> ≥ 10) }()\n",
    "==> { cross-tabulate($_, 'passengerSex', 'passengerSurvival') }()\n",
    "==> to-pretty-table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db9263",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Data wrangling code with multiple languages and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa75cf",
   "metadata": {},
   "source": [
    "Let us demonstrate the *rapid specification of workflows* application by generating data wrangling code from natural language commands. Here is a natural language workflow spec (each row corresponds to a pipeline segment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "74428b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my $commands = q:to/END/;\n",
    "use dataset dfTitanic;\n",
    "rename columns passengerAge as age, passengerSex as sex, passengerClass as class;\n",
    "filter by age ≥ 10;\n",
    "group by 'class' and 'sex';\n",
    "counts;\n",
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99f9ac",
   "metadata": {},
   "source": [
    "### Grammar based interpreters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9e1bc",
   "metadata": {},
   "source": [
    "Here is a table with the generated codes for different programming languages according to the spec above (using [\"DSL::English::DataQueryWorkflows\"](https://raku.land/zef:antononcube/DSL::English::DataQueryWorkflows), [AAp3]): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "408d9217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><thead><tr><th>language</th><th>code</th></tr></thead><tbody><tr><td align=left>Python</td><td align=left>obj = dfTitanic.copy()<br>obj = obj.assign( age = obj[&quot;passengerAge&quot;], sex = obj[&quot;passengerSex&quot;], class = obj[&quot;passengerClass&quot;] )<br>obj = obj[((obj[&quot;age&quot;]&gt;= 10))]<br>obj = obj.groupby([&quot;class&quot;, &quot;sex&quot;])<br>obj = obj.size()</td></tr><tr><td align=left>R</td><td align=left>dfTitanic %&gt;%<br>dplyr::rename(age = passengerAge, sex = passengerSex, class = passengerClass) %&gt;%<br>dplyr::filter(age &gt;= 10) %&gt;%<br>dplyr::group_by(class, sex) %&gt;%<br>dplyr::count()</td></tr><tr><td align=left>Raku</td><td align=left>$obj = dfTitanic ;<br>$obj = rename-columns( $obj, %(&quot;passengerAge&quot; =&gt; &quot;age&quot;, &quot;passengerSex&quot; =&gt; &quot;sex&quot;, &quot;passengerClass&quot; =&gt; &quot;class&quot;) ) ;<br>$obj = $obj.grep({ $_{&quot;age&quot;} &gt;= 10 }).Array ;<br>$obj = group-by($obj, (&quot;class&quot;, &quot;sex&quot;)) ;<br>$obj = $obj&gt;&gt;.elems</td></tr><tr><td align=left>WL</td><td align=left>obj = dfTitanic;<br>obj = Map[ Join[ KeyDrop[ #, {&quot;passengerAge&quot;, &quot;passengerSex&quot;, &quot;passengerClass&quot;} ], &lt;|&quot;age&quot; -&gt; #[&quot;passengerAge&quot;], &quot;sex&quot; -&gt; #[&quot;passengerSex&quot;], &quot;class&quot; -&gt; #[&quot;passengerClass&quot;]|&gt; ]&amp;, obj];<br>obj = Select[ obj, #[&quot;age&quot;] &gt;= 10 &amp; ];<br>obj = GroupBy[ obj, {#[&quot;class&quot;], #[&quot;sex&quot;]}&amp; ];<br>obj = Map[ Length, obj]</td></tr></tbody></table>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "my @tbl = <Python R Raku WL>.map({ %( language => $_, code => ToDSLCode($commands, format=>'code', target => $_) ) });\n",
    "to-html(@tbl, field-names => <language code>, align => 'left').subst(\"\\n\", '<br>', :g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6da24b",
   "metadata": {},
   "source": [
    "Executing the Raku pipeline (by replacing `dfTitanic` with `@dsTitanic` first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52ec56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1st.female => 132, 1st.male => 149, 2nd.female => 96, 2nd.male => 149, 3rd.female => 132, 3rd.male => 332}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $obj = @dsTitanic;\n",
    "$obj = rename-columns( $obj, %(\"passengerAge\" => \"age\", \"passengerSex\" => \"sex\", \"passengerClass\" => \"class\") ) ;\n",
    "$obj = $obj.grep({ $_{\"age\"} >= 10 }).Array ;\n",
    "$obj = group-by($obj, (\"class\", \"sex\")) ;\n",
    "$obj = $obj>>.elems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff0f2a",
   "metadata": {},
   "source": [
    "That is not monadic, of course -- see the monadic version above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571b680",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## LLM generated (via DSL examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c6c1c",
   "metadata": {},
   "source": [
    "Here we define an LLM-examples function for translation of natural language commands into code using DSL examples (provided by \"DSL::Examples\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8b9a325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "&llm-pipeline-segment"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my sub llm-pipeline-segment($lang, $workflow-name = 'DataReshaping') { llm-example-function(dsl-examples(){$lang}{$workflow-name}) };"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b969bb",
   "metadata": {},
   "source": [
    "Here is the LLM translated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a685603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "```perl\n",
       "my $obj = dfTitanic;\n",
       "$obj = rename-columns($obj, %(passengerAge => 'age', passengerSex => 'sex', passengerClass => 'class'));\n",
       "$obj = $obj.grep({ $_{'age'} >= 10 }).Array;\n",
       "$obj = group-by($obj, ('class', 'sex'));\n",
       "say $obj>>.elems;\n",
       "```"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $code = llm-pipeline-segment('Raku', 'DataReshaping')($commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370596e0",
   "metadata": {},
   "source": [
    "Here the translated code *is turned into monadic code* by string manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1817936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "```perl\n",
       "my $obj = dfTitanic;\n",
       "==> {rename-columns($_, %(passengerAge => 'age', passengerSex => 'sex', passengerClass => 'class')) }()\n",
       "==> {$_.grep({ $_{'age'} >= 10 }).Array }()\n",
       "==> {group-by($_, ('class', 'sex')) }()\n",
       "==> {say $_>>.elems}();\n",
       "```"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $code-mon =$code.subst(/ $<lhs>=('$' \\w+) \\h+ '=' \\h+ (\\S*)? $<lhs> (<-[;]>*) ';'/, {\"==> \\{{$0}\\$_{$1} \\}()\"} ):g;\n",
    "$code-mon .= subst(/ $<printer>=[note|say] \\h* $<lhs>=('$' \\w+) ['>>'|»] '.elems' /, {\"==> \\{$<printer> \\$_>>.elems\\}()\"}):g;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a83046",
   "metadata": {},
   "source": [
    "**Remark:** It is assumed that the string manipulation above is insightful of how and why the monadic pipelines simplify imperative code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86421e",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Recommendation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c0497",
   "metadata": {},
   "source": [
    "Here is a computational specification for creating a recommender and obtaining a profile recommendation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "651cc271",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my $spec = q:to/END/;\n",
    "create from @dsTitanic; \n",
    "apply LSI functions IDF, None, Cosine; \n",
    "recommend by profile for passengerSex:male, and passengerClass:1st;\n",
    "join across with @dsTitanic on \"id\";\n",
    "echo the pipeline value;\n",
    "END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b42d9",
   "metadata": {},
   "source": [
    "Here is the Raku code for that spec given as an HTML code snipped with code-highlights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "28c7e23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"none color: inherit; font-weight: 500 .nohighlights { background\" class=\"raku-code\"><div><pre class=\"nohighlights\" style=\"font-size: 1em; font-family: monospace\">SMRMonUnit[]&nbsp;\\[DoubleLongRightArrow]&nbsp;SMRMonCreate[<span style=\"color: #B01030\" class=\"rainbow-name_array\">@dsTitanic</span>]&nbsp;\\[DoubleLongRightArrow]<br>SMRMonApplyTermWeightFunctions[<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">GlobalWeightFunction</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span>&nbsp;<span style=\"color: #008c7e\" class=\"rainbow-keyword\">-&gt;</span>&nbsp;<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">IDF</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #1ca24f\" class=\"rainbow-operator\">,</span>&nbsp;<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">LocalWeightFunction</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span>&nbsp;<span style=\"color: #008c7e\" class=\"rainbow-keyword\">-&gt;</span>&nbsp;<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">None</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #1ca24f\" class=\"rainbow-operator\">,</span>&nbsp;<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">NormalizerFunction</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span>&nbsp;<span style=\"color: #008c7e\" class=\"rainbow-keyword\">-&gt;</span>&nbsp;<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">Cosine</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span>]&nbsp;\\[DoubleLongRightArrow]<br>SMRMonRecommendByProfile[{<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">passengerSex:male</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #1ca24f\" class=\"rainbow-operator\">,</span>&nbsp;<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">passengerClass:1st</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span>}]&nbsp;\\[DoubleLongRightArrow]<br>SMRMonJoinAcross[<span style=\"color: #B01030\" class=\"rainbow-name_array\">@dsTitanic</span><span style=\"color: #1ca24f\" class=\"rainbow-operator\">,</span>&nbsp;<span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span><span style=\"color: #369ec6\" class=\"rainbow-string\">id</span><span style=\"color: #1d90d2\" class=\"rainbow-string_delimiter\">&quot;</span>&nbsp;]&nbsp;\\[DoubleLongRightArrow]<br>SMRMonEchoValue[]</pre></div></div>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%html\n",
    "ToDSLCode($spec, default-targets-spec => 'WL', format => 'code')\n",
    "andthen .subst('.', \"\\n.\", :g)\n",
    "andthen hilite($_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31690ca",
   "metadata": {},
   "source": [
    "Here we execute a slightly modified version of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cf009",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my $obj = ML::SparseMatrixRecommender.new\n",
    ".create-from-wide-form(@dsTitanic)\n",
    ".apply-term-weight-functions(\"IDF\", \"None\", \"Cosine\")\n",
    ".recommend-by-profile([\"passengerSex:male\", \"passengerClass:1st\"])\n",
    ".join-across(@dsTitanic, on => \"id\" )\n",
    ".echo-value(as => {to-pretty-table($_, )} )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437bf650",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Functional parsers (multi-operation pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a386048",
   "metadata": {},
   "source": [
    "In can be said that the package [\"FunctionalParsers\"](https://raku.land/zef:antononcube/FunctionalParsers), [AAp4], implements multi-operator monadic pipelines the creation of parsers and interpreters. \"FunctionalParsers\" achieves that using special infix implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "use FunctionalParsers :ALL;\n",
    "my &p1 = {1} ⨀ symbol('one');\n",
    "my &p2 = {2} ⨀ symbol('two');\n",
    "my &p3 = {3} ⨀ symbol('three');\n",
    "my &p4 = {4} ⨀ symbol('four');\n",
    "my &pH = {10**2} ⨀ symbol('hundred');\n",
    "my &pT = {10**3} ⨀ symbol('thousand');\n",
    "my &pM = {10**6} ⨀ symbol('million');\n",
    "sink my &pNoun = symbol('things') ⨁ symbol('objects');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c95b8c",
   "metadata": {},
   "source": [
    "Here is a parser -- all three monad operations are used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0313dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse sentences that have (1) a digit part, (2) a multiplier part, and (3) a noun\n",
    "my &p = (&p1 ⨁ &p2 ⨁ &p3 ⨁ &p4) ⨂ (&pT ⨁ &pH ⨁ &pM) ⨂ &pNoun;\n",
    "\n",
    "# Interpreter:\n",
    "# (1) flatten the parsed elements\n",
    "# (2) multiply the first two elements and make a sentence with third element\n",
    "sink &p = { \"{$_[0] * $_[1]} $_[2]\"} ⨀ {.flat} ⨀ &p "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828309d",
   "metadata": {},
   "source": [
    "Here the parser is applied to different sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "380c841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000 things\n",
      "100 objects\n",
      "Nil\n"
     ]
    }
   ],
   "source": [
    "['three million things', 'one hundred objects', 'five thousand things']\n",
    "andthen .map({ &p($_.words.List).head.tail })\n",
    "andthen (.say for |$_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984312c4",
   "metadata": {},
   "source": [
    "The last sentence is not parsed because the parser `&p` knows only the digits from 1 to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abc4bf",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## References\n",
    "\n",
    "### Articles, blog posts\n",
    "\n",
    "[Wk1] Wikipedia entry: [Monad (functional programming)](https://en.wikipedia.org/wiki/Monad_(functional_programming)), URL: [https://en.wikipedia.org/wiki/Monad_(functional_programming)](https://en.wikipedia.org/wiki/Monad_(functional_programming)) . \n",
    "\n",
    "[Wk2] Wikipedia entry: [Monad transformer](https://en.wikipedia.org/wiki/Monad_transformer), URL: [https://en.wikipedia.org/wiki/Monad_transformer](https://en.wikipedia.org/wiki/Monad_transformer) .\n",
    "\n",
    "[H1] Haskell.org article: [Monad laws,](https://wiki.haskell.org/Monad_laws) URL: [https://wiki.haskell.org/Monad_laws](https://wiki.haskell.org/Monad_laws). \n",
    "\n",
    "[SH2] Sheng Liang, Paul Hudak, Mark Jones, [\"Monad transformers and modular interpreters\",](http://haskell.cs.yale.edu/wp-content/uploads/2011/02/POPL96-Modular-interpreters.pdf) (1995), Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages. New York, NY: ACM. pp. 333--343. doi:10.1145/199448.199528.\n",
    "\n",
    "[PW1] Philip Wadler, [\"The essence of functional programming\"](https://page.mi.fu-berlin.de/scravy/realworldhaskell/materialien/the-essence-of-functional-programming.pdf), (1992), 19'th Annual Symposium on Principles of Programming Languages, Albuquerque, New Mexico, January 1992.\n",
    "\n",
    "[RW1] Hadley Wickham et al., [dplyr: A Grammar of Data Manipulation](https://github.com/tidyverse/dplyr), (2014), [tidyverse at GitHub](https://github.com/tidyverse), URL: [https://github.com/tidyverse/dplyr](https://github.com/tidyverse/dplyr) .\n",
    "       (See also, [http://dplyr.tidyverse.org](http://dplyr.tidyverse.org) .)\n",
    "\n",
    "[AA1] Anton Antonov, [\"Monad code generation and extension\"](https://mathematicaforprediction.wordpress.com/2017/06/23/monad-code-generation-and-extension/), (2017), [MathematicaForPrediction at WordPress](https://mathematicaforprediction.wordpress.com).\n",
    "\n",
    "[AA2] Anton Antonov, [\"Monad laws in Raku\"](https://rakuforprediction.wordpress.com/2025/11/16/monad-laws-in-raku/), (2025), [RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[AA3] Anton Antonov, [\"Day 2 – Doing Data Science with Raku\"](https://raku-advent.blog/2025/12/02/day-2-doing-data-science-with-raku/), (2025), [Raku Advent Calendar at WordPress](https://raku-advent.blog/).\n",
    "\n",
    "### Packages\n",
    "\n",
    "[AAp1] Anton Antonov, [MonadMakers](https://resources.wolframcloud.com/PacletRepository/resources/AntonAntonov/MonadMakers/), Wolfram Language paclet, (2023), [Wolfram Language Paclet Repository](https://resources.wolframcloud.com/PacletRepository/).\n",
    "\n",
    "[AAp2] Anton Antonov, [StatStateMonadCodeGeneratoreNon](https://github.com/antononcube/R-packages/tree/master/StateMonadCodeGenerator), R package, (2019-2024), \n",
    "[GitHub/@antononcube](https://github.com/antononcube/).\n",
    "\n",
    "[AAp3] Anton Antonov, [DSL::English::DataQueryWorkflows](https://github.com/antononcube/Raku-DSL-English-DataQueryWorkflows), Raku package, (2020-2024), \n",
    "[GitHub/@antononcube](https://github.com/antononcube/).\n",
    "\n",
    "[AAp4] Anton Antonov, [FunctionalParsers](https://github.com/antononcube/Raku-FunctionalParsers), Raku package, (2023-2024), \n",
    "[GitHub/@antononcube](https://github.com/antononcube/).\n",
    "\n",
    "### Videos\n",
    "\n",
    "[AAv1] Anton Antonov, [Monadic Programming: With Application to Data Analysis, Machine Learning and Language Processing](https://www.youtube.com/watch?v=_cIFA5GHF58), (2017), Wolfram Technology Conference 2017 presentation. [YouTube/WolframResearch](https://www.youtube.com/@WolframResearch).\n",
    "\n",
    "[AAv2] Anton Antonov, [Raku for Prediction](https://www.youtube.com/watch?v=frpCBjbQtnA), (2021), [The Raku Conference 2021](https://www.youtube.com/@therakuconference6823).\n",
    "\n",
    "[AAv3] Anton Antonov, [Simplified Machine Learning Workflows Overview](https://www.youtube.com/watch?v=Xy7eV8wRLbE), (2022), Wolfram Technology Conference 2022 presentation. [YouTube/WolframResearch](https://www.youtube.com/@WolframResearch).\n",
    "\n",
    "[AAv4] Anton Antonov, [Simplified Machine Learning Workflows Overview (Raku-centric)](https://www.youtube.com/watch?v=p3iwPsc6e74), (2022), Wolfram Technology Conference 2022 presentation. [YouTube/@AAA4prediction](https://www.youtube.com/@AAA4prediction).\n",
    "\n",
    "[AAv5] Anton Antonov, [Applications of Monadic Programming, Part 1, Questions & Answers](https://www.youtube.com/watch?v=Xz5B4B0kVco), (2025), [YouTube/@AAA4prediction](https://www.youtube.com/@AAA4prediction).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
